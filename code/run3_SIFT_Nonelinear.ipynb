{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH="
      ],
      "metadata": {
        "id": "UJCh83reDY3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.12-Linux-x86_64.sh\n",
        " MINICONDA_PREFIX=/usr/local \n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT \n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT \n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "7b3brsNvDul2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.7 --yes \n",
        "conda update --channel defaults --all --yes"
      ],
      "metadata": {
        "id": "ZlAkg6Z0D2eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "metadata": {
        "id": "xwteNGW_t7TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ],
      "metadata": {
        "id": "A7xAbruNuA6J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge cyvlfeat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDFnR4ACGXua",
        "outputId": "ce59d856-a428-465f-c25b-9a6e0c3a2132"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cyvlfeat\n",
            "\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2022.4.26-~ --> conda-forge::ca-certificates-2021.10.8-ha878542_0\n",
            "  certifi            pkgs/main::certifi-2021.10.8-py37h06a~ --> conda-forge::certifi-2021.10.8-py37h89c1867_2\n",
            "  conda              pkgs/main::conda-4.12.0-py37h06a4308_0 --> conda-forge::conda-4.12.0-py37h89c1867_0\n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "Preparing transaction: | \b\bdone\n",
            "Verifying transaction: - \b\bdone\n",
            "Executing transaction: | \b\bdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wSJl6PRSGZiv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ofM0bB01-EA_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from glob import glob\n",
        "import cyvlfeat\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FjVRB6KF-KwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93b29a5-1f72-4a5e-9ba3-d1b94b3b2cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 75.67it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 107.50it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 119.41it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 108.69it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 104.92it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 128.57it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 120.52it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 128.42it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 172.88it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 175.06it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 133.92it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 165.01it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 181.00it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 175.23it/s]\n",
            "100%|██████████| 100/100 [00:00<00:00, 169.34it/s]\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "train_data_base_path = \"/content/drive/MyDrive/training\"\n",
        "test_data_base_path = \"/content/drive/MyDrive/testing\"\n",
        "train_X = []\n",
        "train_y = []\n",
        "test=[]\n",
        "categorys = os.listdir(train_data_base_path)\n",
        "if categorys.__contains__('.DS_Store'):\n",
        "    categorys.remove('.DS_Store')\n",
        "for category in categorys:\n",
        "  train_data_path = glob(os.path.join(train_data_base_path, category, '*.jpg'))\n",
        "  for file in tqdm(train_data_path):\n",
        "    image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "    #\n",
        "    image = (image - np.mean(image))/np.std(image)\n",
        "    #\n",
        "    image = (image-np.min(image))/(np.max(image)-np.min(image))\n",
        "\n",
        "    train_X.append(image)\n",
        "    train_y.append(category)\n",
        "for file in glob(os.path.join(test_data_base_path, '*.jpg')):\n",
        "  image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "  test.append(image)\n",
        "#encode label\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_y)\n",
        "train_y = le.transform(train_y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X[0:3])\n",
        "print(train_y[0:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D9AMz2u97Iq",
        "outputId": "b836131f-7db3-496c-8441-fca66e10f6c1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0.80237154, 0.51383399, 0.22529644, ..., 0.40316206, 0.27667984,\n",
            "        0.33201581],\n",
            "       [0.38735178, 0.27272727, 0.16205534, ..., 0.49407115, 0.46640316,\n",
            "        0.52173913],\n",
            "       [0.12252964, 0.12252964, 0.12648221, ..., 0.39920949, 0.46640316,\n",
            "        0.51383399],\n",
            "       ...,\n",
            "       [0.97233202, 0.96442688, 0.94466403, ..., 0.96047431, 0.95652174,\n",
            "        0.95652174],\n",
            "       [0.96442688, 0.95652174, 0.94466403, ..., 0.95256917, 0.95652174,\n",
            "        0.95652174],\n",
            "       [0.94466403, 0.94466403, 0.94466403, ..., 0.9486166 , 0.95652174,\n",
            "        0.95652174]]), array([[0.80314961, 0.80314961, 0.80314961, ..., 0.96062992, 0.96062992,\n",
            "        0.96062992],\n",
            "       [0.80314961, 0.80314961, 0.80708661, ..., 0.96062992, 0.96062992,\n",
            "        0.96062992],\n",
            "       [0.80314961, 0.80708661, 0.80708661, ..., 0.96062992, 0.96062992,\n",
            "        0.96062992],\n",
            "       ...,\n",
            "       [0.59448819, 0.57874016, 0.61023622, ..., 0.62992126, 0.5984252 ,\n",
            "        0.58661417],\n",
            "       [0.61417323, 0.59055118, 0.61023622, ..., 0.62204724, 0.58661417,\n",
            "        0.57874016],\n",
            "       [0.65354331, 0.61811024, 0.62204724, ..., 0.6023622 , 0.58267717,\n",
            "        0.57480315]]), array([[0.38431373, 0.38431373, 0.38431373, ..., 0.39607843, 0.4       ,\n",
            "        0.4       ],\n",
            "       [0.38431373, 0.38431373, 0.38823529, ..., 0.39607843, 0.39607843,\n",
            "        0.39607843],\n",
            "       [0.38823529, 0.38823529, 0.38823529, ..., 0.4       , 0.4       ,\n",
            "        0.4       ],\n",
            "       ...,\n",
            "       [0.02745098, 0.02352941, 0.02352941, ..., 0.54901961, 0.54901961,\n",
            "        0.54901961],\n",
            "       [0.02745098, 0.02352941, 0.02352941, ..., 0.55686275, 0.55294118,\n",
            "        0.55294118],\n",
            "       [0.02745098, 0.02352941, 0.02352941, ..., 0.56078431, 0.54509804,\n",
            "        0.54509804]])]\n",
            "[8 8 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QiceLyiY8X_o"
      },
      "outputs": [],
      "source": [
        "#get sift dfit phow feature\n",
        "def get_sift_feature(X,sift_type = \"dsift\"):\n",
        "  num = 0\n",
        "  features = []\n",
        "  if sift_type == \"sift\":\n",
        "    feature_generate = cyvlfeat.sift.sift\n",
        "  elif sift_type == \"dsift\":\n",
        "    feature_generate = cyvlfeat.sift.dsift\n",
        "  elif sift_type == \"phow\":\n",
        "    feature_generate = cyvlfeat.sift.phow\n",
        "  for image in tqdm(X):\n",
        "    if sift_type == \"sift\":\n",
        "      feature = feature_generate(image)\n",
        "    else:\n",
        "      _,feature = feature_generate(image,step = 4)\n",
        "    features.append(feature) \n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jshdU9TwMQIu"
      },
      "outputs": [],
      "source": [
        "#kmeans \n",
        "def get_kmeans_centers(feature):\n",
        "  # creat feature array\n",
        "  for i in range(0,len(feature)):\n",
        "    if i == 0:\n",
        "      feature_new = feature[i]\n",
        "    else:\n",
        "      feature_new = np.append(feature_new,feature[i],axis = 0)\n",
        "  #set kmeans\n",
        "  kmeans = MiniBatchKMeans(n_clusters=500)       \n",
        "  kmeans.fit(feature_new)\n",
        "  return kmeans "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get hog feature\n",
        "def get_hog_feature(kmeans,feature): \n",
        "  hog_feature = []\n",
        "  for i in tqdm(range(0,len(feature))):\n",
        "    vocab = np.zeros(len(kmeans.cluster_centers_))\n",
        "    res=kmeans.predict(feature[i])\n",
        "    for data in res:\n",
        "      vocab[data] +=1 \n",
        "    hog_feature.append(vocab)\n",
        "  return hog_feature"
      ],
      "metadata": {
        "id": "mtrmbTYSj02c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sift_hog_classifier(X,y,classifier = \"SVM\"):\n",
        "  X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.3)\n",
        "  if  classifier == \"SVM\":\n",
        "    clf = SVC(C=30)\n",
        "  elif classifier == \"RFC\":\n",
        "    clf = RandomForestClassifier()\n",
        "  elif classifier == \"LR\":\n",
        "    clf = LogisticRegression(C=10)\n",
        "  elif classifier == \"MLP\":\n",
        "    clf = KNeighborsClassifier()\n",
        "  clf = clf.fit(X_train,y_train)\n",
        "  y_hat_train = clf.predict(X_train)\n",
        "  y_hat_val = clf.predict(X_val)\n",
        "  print(\"--------------\"+classifier+\"--------------\")\n",
        "  print(\"train accuracy:\"+str(accuracy_score(y_train,y_hat_train)))\n",
        "  print(\"val accuracy:\"+str(accuracy_score(y_val,y_hat_val)))\n"
      ],
      "metadata": {
        "id": "nl8uMWYRxn_v"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sift_feature = get_sift_feature(train_X,\"sift\")\n",
        "dsift_feature = get_sift_feature(train_X,\"dsift\")\n",
        "phow_feature = get_sift_feature(train_X,\"phow\")\n",
        "print(phow_feature[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0LVC3Lxa8yB",
        "outputId": "c4029f69-a4ba-4ed1-e1c7-ef7c97d6d321"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [00:42<00:00, 35.41it/s]\n",
            "100%|██████████| 1500/1500 [04:17<00:00,  5.82it/s]\n",
            "100%|██████████| 1500/1500 [01:55<00:00, 13.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[ 27,  32,  16, ...,  13,  37,  34],\n",
            "       [ 32,  40,  25, ...,  63,  46,   4],\n",
            "       [  9,   3,  10, ...,  21,  23,   6],\n",
            "       ...,\n",
            "       [  9,  40, 140, ...,   6,  12,   1],\n",
            "       [  8,  40, 150, ...,   6,  12,   2],\n",
            "       [  5,  24, 147, ...,   6,  10,   3]], dtype=uint8), array([[  0,   0,   0, ...,   0,   0,   0],\n",
            "       [  0,   0,   0, ...,   0,   0,   0],\n",
            "       [  0,   0,   0, ...,   0,   0,   0],\n",
            "       ...,\n",
            "       [  0,   0,  59, ...,   5,   1,   1],\n",
            "       [  0,   0, 113, ...,  10,   0,   1],\n",
            "       [  0,   0, 129, ...,  17,   0,   0]], dtype=uint8), array([[ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       ...,\n",
            "       [ 1,  7, 45, ...,  7,  7,  0],\n",
            "       [ 0,  3, 28, ..., 13, 17,  0],\n",
            "       [ 0,  0, 18, ..., 18, 30,  0]], dtype=uint8), array([[ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       ...,\n",
            "       [ 1,  1,  7, ...,  1,  0,  5],\n",
            "       [ 1,  0,  6, ...,  4,  7,  9],\n",
            "       [ 1,  0, 11, ...,  7, 22, 14]], dtype=uint8), array([[ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       ...,\n",
            "       [ 3,  9,  8, ..., 12, 21,  3],\n",
            "       [ 3, 11, 10, ..., 26, 42, 11],\n",
            "       [ 3, 13, 14, ..., 31, 75, 31]], dtype=uint8), array([[ 41,  45, 107, ...,  37,  65,  52],\n",
            "       [ 15,   4,  16, ...,  43,  20,  15],\n",
            "       [ 40,  32,  32, ...,  31,  27,  41],\n",
            "       ...,\n",
            "       [  1,   4,  10, ...,  32,  38,  40],\n",
            "       [  1,   4,  11, ...,  15,  33,  29],\n",
            "       [  1,   4,  14, ...,   7,  36,  17]], dtype=uint8), array([[  0,   0,   0, ...,   0,   0,   0],\n",
            "       [  0,   0,   0, ...,   0,   0,   0],\n",
            "       [ 14,   3,  34, ...,   4,  11,  25],\n",
            "       ...,\n",
            "       [ 28,  28,  12, ...,  96, 122,  38],\n",
            "       [ 11,   9,  12, ..., 140, 131,  16],\n",
            "       [  6,   3,  11, ..., 143, 143,   4]], dtype=uint8), array([[ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       ...,\n",
            "       [ 0,  0,  0, ..., 20, 12,  2],\n",
            "       [ 0,  0,  0, ..., 15,  8,  7],\n",
            "       [ 0,  0,  0, ...,  6,  4, 16]], dtype=uint8), array([[  7,   3,   3, ...,  10,  26,  65],\n",
            "       [  3,   3,  17, ...,  75,  33,  56],\n",
            "       [ 39,  14,  16, ...,  29,   1,   6],\n",
            "       ...,\n",
            "       [  0,   0,   0, ...,  42, 166,   9],\n",
            "       [  0,   0,   0, ...,   8, 164,  14],\n",
            "       [  0,   0,   0, ...,   0, 169,  18]], dtype=uint8), array([[ 9, 70, 52, ...,  0,  2, 15],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       [ 0,  0,  0, ...,  0,  0,  0],\n",
            "       ...,\n",
            "       [ 8, 11, 30, ...,  4,  4, 10],\n",
            "       [10, 16, 33, ...,  8,  6, 13],\n",
            "       [ 8, 16, 47, ..., 13,  9, 10]], dtype=uint8)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "kmeans_sift = get_kmeans_centers(sift_feature)\n",
        "hog_sift_feature = get_hog_feature(kmeans_sift,sift_feature)\n",
        "del kmeans_sift\n",
        "gc.collect()\n",
        "kmeans_dsift = get_kmeans_centers(dsift_feature)\n",
        "hog_dsift_feature =get_hog_feature(kmeans_dsift,dsift_feature)\n",
        "del kmeans_dsift\n",
        "gc.collect()\n",
        "kmeans_phow = get_kmeans_centers(phow_feature)\n",
        "hog_phow_feature =get_hog_feature(kmeans_phow,phow_feature)\n",
        "del kmeans_phow\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpv0qJAU4IEX",
        "outputId": "98df2e68-e254-4f19-ff80-ba8bc6352f19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1500/1500 [00:01<00:00, 1017.02it/s]\n",
            "100%|██████████| 1500/1500 [00:26<00:00, 56.38it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the feature extracted by resNet\n",
        "training_features = np.load(\"/content/drive/MyDrive/training_features.npy\")\n",
        "training_labels = np.load(\"/content/drive/MyDrive/training_labels.npy\")"
      ],
      "metadata": {
        "id": "YtQps-VJMSEl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sift_hog_classifier(hog_sift_feature,train_y,classifier = \"SVM\")\n",
        "sift_hog_classifier(hog_dsift_feature,train_y,classifier = \"SVM\")\n",
        "sift_hog_classifier(hog_phow_feature,train_y,classifier = \"SVM\")\n",
        "\n",
        "sift_hog_classifier(training_features,training_labels,classifier = \"SVM\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15mgG5vV5IaF",
        "outputId": "a59b79e3-8303-4e78-9408-0d5077c10d2e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------SVM--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.29777777777777775\n",
            "--------------SVM--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.6933333333333334\n",
            "--------------SVM--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sift_hog_classifier(hog_sift_feature,train_y,classifier = \"RFC\")\n",
        "sift_hog_classifier(hog_dsift_feature,train_y,classifier = \"RFC\")\n",
        "sift_hog_classifier(hog_phow_feature,train_y,classifier = \"RFC\")\n",
        "\n",
        "sift_hog_classifier(training_features,training_labels,classifier = \"RFC\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUUW_mOE-YLN",
        "outputId": "37e0fdce-5413-431c-ce6d-b803a60419d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------RFC--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.24444444444444444\n",
            "--------------RFC--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.68\n",
            "--------------RFC--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.5111111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sift_hog_classifier(hog_sift_feature,train_y,classifier = \"LR\")\n",
        "sift_hog_classifier(hog_dsift_feature,train_y,classifier = \"LR\")\n",
        "sift_hog_classifier(hog_phow_feature,train_y,classifier = \"LR\")\n",
        "\n",
        "sift_hog_classifier(training_features,training_labels,classifier = \"LR\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVdDoF2R-Yzq",
        "outputId": "27cf7bde-588f-4713-89bd-4d2d33d38643"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------LR--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.20666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------LR--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.6755555555555556\n",
            "--------------LR--------------\n",
            "train accuracy:1.0\n",
            "val accuracy:0.5638888888888889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sift_hog_classifier(hog_sift_feature,train_y,classifier = \"MLP\")\n",
        "sift_hog_classifier(hog_dsift_feature,train_y,classifier = \"MLP\")\n",
        "sift_hog_classifier(hog_phow_feature,train_y,classifier = \"MLP\")\n",
        "\n",
        "sift_hog_classifier(training_features,training_labels,classifier = \"MLP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia2c-DGs-Z3j",
        "outputId": "7576c5aa-e224-41c1-e96c-cc764e1c4ab9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------MLP--------------\n",
            "train accuracy:0.2542857142857143\n",
            "val accuracy:0.16444444444444445\n",
            "--------------MLP--------------\n",
            "train accuracy:0.6847619047619048\n",
            "val accuracy:0.52\n",
            "--------------MLP--------------\n",
            "train accuracy:0.6130952380952381\n",
            "val accuracy:0.3638888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y5cgLnf5fj6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_Cuuy0oNfnaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "run3_SIFT_Nonelinear.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}